<!DOCTYPE html><html lang="zh-Hans"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="PyTorch入门: Kaggle 泰坦尼克幸存者预测"><meta name="keywords" content="Magolor,人工智能,机器学习,神经网络,Kaggle,Python,PyTorch,Kaggle 泰坦尼克幸存者预测"><meta name="author" content="Magolor"><meta name="copyright" content="Magolor"><title>PyTorch入门: Kaggle 泰坦尼克幸存者预测 | Magolor</title><link rel="shortcut icon" href="/Magolor-OC-trans-avatar-rd-64.ico"><link rel="stylesheet" href="/css/index.css?version=1.7.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.7.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/gh/upupming/gitalk@36368e5dffd049e956cdbbd751ff96c28d8255cf/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><link rel="dns-prefetch" href="https://hm.baidu.com"><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?cb418bedbb9a29dbb6d61e55c68bccc5";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();</script><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#数据预处理"><span class="toc-text"> 数据预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#补足age数据"><span class="toc-text"> 补足Age数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#补足embarked数据"><span class="toc-text"> 补足Embarked数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#补足fare数据"><span class="toc-text"> 补足Fare数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据离散化one-hot-encoding"><span class="toc-text"> 数据离散化(One-hot Encoding)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据归一化normalization"><span class="toc-text"> 数据归一化(Normalization)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#代码实现"><span class="toc-text"> 代码实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#pytorch构建全连接深度神经网络"><span class="toc-text"> PyTorch构建全连接深度神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#集成ensemble"><span class="toc-text"> 集成(Ensemble)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#完整代码"><span class="toc-text"> 完整代码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#效果"><span class="toc-text"> 效果</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/Magolor-OC-trans-avatar.png"></div><div class="author-info__name text-center">Magolor</div><div class="author-info__description text-center">AFO的OIer；AI专业在读；业余作曲 (b站网易云Talirian)；业余科幻小说创作；科技至上主义者；蜂巢意识形态</div><div class="follow-button"><a href="https://magolor.cn/2018/07/22/2018-07-22-blog-01/">博主简介</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">42</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">46</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">12</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">友链</div><a class="author-info-links__name text-center" href="https://rqy.moe" rel="external nofollow noopener noreferrer" target="_blank">_rqy</a><a class="author-info-links__name text-center" href="https://blog.csdn.net/wxh010910" rel="external nofollow noopener noreferrer" target="_blank">wxh010910</a><a class="author-info-links__name text-center" href="https://www.cnblogs.com/GXZlegend" rel="external nofollow noopener noreferrer" target="_blank">GXZlegend</a><a class="author-info-links__name text-center" href="https://www.cnblogs.com/RabbitHu" rel="external nofollow noopener noreferrer" target="_blank">RabbitHu</a><a class="author-info-links__name text-center" href="https://crazyinventor494388371.wordpress.com" rel="external nofollow noopener noreferrer" target="_blank">Vision</a><a class="author-info-links__name text-center" href="https://blog.xehoth.cc" rel="external nofollow noopener noreferrer" target="_blank">xehoth</a><a class="author-info-links__name text-center" href="https://blog.csdn.net/mys_c_k" rel="external nofollow noopener noreferrer" target="_blank">Mys_C_K</a><a class="author-info-links__name text-center" href="https://www.cnblogs.com/suncongbo" rel="external nofollow noopener noreferrer" target="_blank">suncongbo</a><a class="author-info-links__name text-center" href="https://www.cnblogs.com/Tian-Xing-Sakura" rel="external nofollow noopener noreferrer" target="_blank">Tian Xing</a><a class="author-info-links__name text-center" href="https://www.cnblogs.com/mlystdcall" rel="external nofollow noopener noreferrer" target="_blank">__stdcall</a><a class="author-info-links__name text-center" href="https://cydiater.me" rel="external nofollow noopener noreferrer" target="_blank">Cydiater</a><a class="author-info-links__name text-center" href="https://blog.csdn.net/icefox_zhx" rel="external nofollow noopener noreferrer" target="_blank">icefox</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(/img/Beneath_the_Starlight_16-9.png)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Magolor</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">首页</a><a class="site-page" href="/archives">文章</a><a class="site-page" href="/slides">幻灯片</a><a class="site-page" href="/categories">归档</a><a class="site-page" href="/tags">标签</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> 搜索</span></a></span></div><div id="post-info"><div id="post-title">PyTorch入门: Kaggle 泰坦尼克幸存者预测</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-01-12</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/人工智能/">人工智能</a><i class="fa fa-angle-right" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/人工智能/神经网络/">神经网络</a><div class="post-meta-wordcount"><span>字数总计: </span><span class="word-count">4k</span><span class="post-meta__separator">|</span><span>阅读时长: 18 分钟</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p>刚刚学了PyTorch，写个神经网络试试…</p>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><p><a href="https://www.kaggle.com/c/titanic" rel="external nofollow noopener noreferrer" target="_blank">Kaggle比赛地址</a></p>
<p>给定泰坦尼克号上<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>891</mn></mrow><annotation encoding="application/x-tex">891</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span><span class="mord">9</span><span class="mord">1</span></span></span></span>名乘客的信息: 姓名、性别、年龄、船票等级、家属等，以及这些乘客是否存活。目标是判断另外<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>418</mn></mrow><annotation encoding="application/x-tex">418</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">4</span><span class="mord">1</span><span class="mord">8</span></span></span></span>名乘客是否存活。</p>
<p>使用PyTorch训练一个神经网络来完成这个任务。</p>
<a id="more"></a>
<h2 id="数据预处理"><a class="markdownIt-Anchor" href="#数据预处理"></a> 数据预处理</h2>
<p>首先描述一下数据预处理的过程。</p>
<p><img src="/img/2020-01-12-blog-01/data.png" alt></p>
<p>观察一下，<s>主观臆断</s>初步分析和感觉可以得出: 乘客编号(PassengerId)应该是完全没用的信息；姓名(Name)似乎和存活关系也不大；船票号(Ticket)由于数据太杂乱了，有用，但是应该会很麻烦；如果知道泰坦尼克号每个隔间的位置以及逃生通道的位置，隔间号(Cabin)应该是非常重要的信息，然而数据缺失特别严重，这意味着将其作为重要标准会有问题。</p>
<p>因此只利用其他数据: 船票等级(Pclass), 姓名(Name), 性别(Sex), 年龄(Age), 登船兄弟个数(SibSp), 登船长辈个数(Parch), 票价(Fare), 登船港口(Embarked)。还需要对这些数据进行预处理。</p>
<br>
<h3 id="补足age数据"><a class="markdownIt-Anchor" href="#补足age数据"></a> 补足Age数据</h3>
<p><s>看一眼就可以发现</s>在Excel中筛选或用pandas的<code>isnull()</code>函数检查发现，训练集和测试集年龄数据都存在大量缺失。存在大规模数据缺失问题，一般可以采取的方法有: 均值填补、中位数填补、众数填补、矩阵分解补全、随机森林、预设未知项等等。尝试发现均值和中位数填补方法效果不好，票价很多导致众数在这道题中不够明显，矩阵分解补全和随机森林又比较复杂(不过可以引用一些写好的库)，因此采用预设未知项。补充UknAge属性表示不知道年龄，对于Age缺失的数据将此项设置为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>。(感性理解可以认为将来神经网络会利用UknAge的权重来动态为缺失项填补一个估计值)。</p>
<p>(网上的随机森林做法我感到非常疑惑，如果说兄弟个数和长辈个数还勉强可以反映年龄(即使这里只记录了登船的亲属个数)，那为什么年龄和性别会有关联？用性别参与预测年龄有什么依据？)</p>
<br>
<h3 id="补足embarked数据"><a class="markdownIt-Anchor" href="#补足embarked数据"></a> 补足Embarked数据</h3>
<p><s>某次运行Python程序得到少量NaN输出结果于是发现</s>在Excel中筛选或用pandas的<code>isnull()</code>函数检查发现，训练集登船港口数据有2人缺失。登船港口应该会和什么有关呢？个人感觉登船港口不同可能导致里程不同，从而影响票价，发现缺失数据的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span>人票价都为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>80</mn></mrow><annotation encoding="application/x-tex">80</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span><span class="mord">0</span></span></span></span>。同时为了控制变量，性别、船票等级都会影响票价，因此筛选所有票价在<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>75</mn><mo>∼</mo><mn>85</mn></mrow><annotation encoding="application/x-tex">75 \sim 85</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">7</span><span class="mord">5</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span><span class="mord">5</span></span></span></span>之间的男性头等舱船票。</p>
<p><img src="/img/2020-01-12-blog-01/Embarked.png" alt></p>
<p>发现大多数来自于C港口。因此可以假定缺失数据的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span></span></span></span>人从C港口登陆。</p>
<br>
<h3 id="补足fare数据"><a class="markdownIt-Anchor" href="#补足fare数据"></a> 补足Fare数据</h3>
<p><s>再次运行Python程序得到少量NaN输出结果于是发现</s>在Excel中筛选或用pandas的<code>isnull()</code>函数检查发现，测试集有<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>人票价数据缺失。</p>
<p><img src="/img/2020-01-12-blog-01/Fare.png" alt></p>
<p>根据此前对票价影响因素的分析，用相同登船港口、船票等级、性别的乘客取中位数来作为预测票价(均值明显偏高)。得出<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>14.4</mn></mrow><annotation encoding="application/x-tex">14.4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">4</span><span class="mord">.</span><span class="mord">4</span></span></span></span>。</p>
<br>
<h3 id="数据离散化one-hot-encoding"><a class="markdownIt-Anchor" href="#数据离散化one-hot-encoding"></a> 数据离散化(One-hot Encoding)</h3>
<p>为了方便神经网络处理，应该将离散数据都拆成多项。例如将登船港口拆分为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">3</span></span></span></span>个属性，“是否从C港口登船”，“是否从Q港口登船”，“是否从S港口登船”，每个属性都是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn><mi mathvariant="normal">/</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">0/1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">0</span><span class="mord">/</span><span class="mord">1</span></span></span></span>二值。因此经过离散化，最终得到了<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>26</mn></mrow><annotation encoding="application/x-tex">26</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">6</span></span></span></span>个不同的属性(加上是否存活的label一共<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>27</mn></mrow><annotation encoding="application/x-tex">27</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mord">7</span></span></span></span>个属性):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">NEW_INDEX = [<span class="string">'Age'</span>, <span class="string">'UknAge'</span>, <span class="string">'Fare'</span>,</span><br><span class="line">             <span class="string">'Pclass_0'</span>, <span class="string">'Pclass_1'</span>, <span class="string">'Pclass_2'</span>,</span><br><span class="line">             <span class="string">'Sex_0'</span>, <span class="string">'Sex_1'</span>,</span><br><span class="line">             <span class="string">'SibSp_0'</span>, <span class="string">'SibSp_1'</span>, <span class="string">'SibSp_2'</span>, <span class="string">'SibSp_3'</span>, <span class="string">'SibSp_4'</span>, <span class="string">'SibSp_5'</span>, <span class="string">'SibSp_8'</span>,</span><br><span class="line">             <span class="string">'Parch_0'</span>, <span class="string">'Parch_1'</span>, <span class="string">'Parch_2'</span>, <span class="string">'Parch_3'</span>, <span class="string">'Parch_4'</span>, <span class="string">'Parch_5'</span>, <span class="string">'Parch_6'</span>, <span class="string">'Parch_9'</span>,</span><br><span class="line">             <span class="string">'Embarked_0'</span>, <span class="string">'Embarked_1'</span>, <span class="string">'Embarked_2'</span>,</span><br><span class="line">             <span class="string">'Survived'</span></span><br><span class="line">            ]</span><br></pre></td></tr></table></figure>
<br>
<h3 id="数据归一化normalization"><a class="markdownIt-Anchor" href="#数据归一化normalization"></a> 数据归一化(Normalization)</h3>
<p>为了方便神经网络处理，将所有数值转化为介于<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn><mo>∼</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">0 \sim 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>之间的数值。~~叒运行Python程序全部得到NaN输出结果于是注意到，~~不能直接全部除以最大值，而需要判断最大值是否非<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>(刚刚用<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>填充NaN的列最大值可能为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span></span></span></span>)。</p>
<br>
<h3 id="代码实现"><a class="markdownIt-Anchor" href="#代码实现"></a> 代码实现</h3>
<p>最开始直接裸写…那叫一个痛苦，代码又臭又长…<s>对于压行教信徒的我简直是奇耻大辱</s></p>
<p>于是去学了numpy和pandas入门…重构了无数次代码以后变成了下面勉强可以接受的样子…</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Configurations</span></span><br><span class="line">OLD_INDEX = [<span class="string">'Pclass'</span>,<span class="string">'Sex'</span>,<span class="string">'Age'</span>,<span class="string">'UknAge'</span>,<span class="string">'SibSp'</span>,<span class="string">'Parch'</span>,<span class="string">'Fare'</span>,<span class="string">'Embarked'</span>,<span class="string">'Survived'</span>]</span><br><span class="line">NEW_INDEX = [<span class="string">'Age'</span>, <span class="string">'UknAge'</span>, <span class="string">'Fare'</span>,</span><br><span class="line">             <span class="string">'Pclass_0'</span>, <span class="string">'Pclass_1'</span>, <span class="string">'Pclass_2'</span>,</span><br><span class="line">             <span class="string">'Sex_0'</span>, <span class="string">'Sex_1'</span>,</span><br><span class="line">             <span class="string">'SibSp_0'</span>, <span class="string">'SibSp_1'</span>, <span class="string">'SibSp_2'</span>, <span class="string">'SibSp_3'</span>, <span class="string">'SibSp_4'</span>, <span class="string">'SibSp_5'</span>, <span class="string">'SibSp_8'</span>,</span><br><span class="line">             <span class="string">'Parch_0'</span>, <span class="string">'Parch_1'</span>, <span class="string">'Parch_2'</span>, <span class="string">'Parch_3'</span>, <span class="string">'Parch_4'</span>, <span class="string">'Parch_5'</span>, <span class="string">'Parch_6'</span>, <span class="string">'Parch_9'</span>,</span><br><span class="line">             <span class="string">'Embarked_0'</span>, <span class="string">'Embarked_1'</span>, <span class="string">'Embarked_2'</span>,</span><br><span class="line">             <span class="string">'Survived'</span></span><br><span class="line">            ]</span><br><span class="line">MAP_Sex = &#123;<span class="string">'male'</span>:<span class="number">0</span>,<span class="string">'female'</span>:<span class="number">1</span>&#125;</span><br><span class="line">MAP_Embarked = &#123;<span class="string">'C'</span>:<span class="number">0</span>,<span class="string">'Q'</span>:<span class="number">1</span>,<span class="string">'S'</span>:<span class="number">2</span>&#125;</span><br><span class="line">ONE_HOT = [[<span class="number">1</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">1</span>]]</span><br><span class="line">FEATURES = <span class="number">26</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span><span class="params">( data )</span>:</span></span><br><span class="line">    <span class="comment"># Data Cleaning</span></span><br><span class="line">    data = pd.DataFrame(data,columns=OLD_INDEX)</span><br><span class="line">    data[<span class="string">'UknAge'</span>] = data[<span class="string">'UknAge'</span>].fillna(<span class="number">0</span>)</span><br><span class="line">    data[<span class="string">'Survived'</span>] = data[<span class="string">'Survived'</span>].fillna(<span class="number">0</span>)</span><br><span class="line">    <span class="comment">#### print(data[data['Age'].isnull()])</span></span><br><span class="line">    data.loc[data[<span class="string">'Age'</span>].isnull(),<span class="string">'UknAge'</span>] = <span class="number">1</span></span><br><span class="line">    data[<span class="string">'Age'</span>] = data[<span class="string">'Age'</span>].fillna(<span class="number">0</span>)</span><br><span class="line">    <span class="comment">#### print(data[data['Fare'].isnull()])</span></span><br><span class="line">    data[<span class="string">'Fare'</span>] = data[<span class="string">'Fare'</span>].fillna(<span class="number">14.4</span>)</span><br><span class="line">    <span class="comment">#### print(data[data['Embarked'].isnull()])</span></span><br><span class="line">    data[<span class="string">'Embarked'</span>] = data[<span class="string">'Embarked'</span>].fillna(<span class="string">'C'</span>)</span><br><span class="line">    <span class="comment">#### One-hot Encoding</span></span><br><span class="line">    data[<span class="string">'Pclass'</span>] -= <span class="number">1</span></span><br><span class="line">    data[<span class="string">'Sex'</span>] = data[<span class="string">'Sex'</span>].map(MAP_Sex)</span><br><span class="line">    data[<span class="string">'Embarked'</span>] = data[<span class="string">'Embarked'</span>].map(MAP_Embarked)</span><br><span class="line">    data = pd.get_dummies(data,columns=[<span class="string">'Pclass'</span>,<span class="string">'Sex'</span>,<span class="string">'SibSp'</span>,<span class="string">'Parch'</span>,<span class="string">'Embarked'</span>])</span><br><span class="line">    data = pd.DataFrame(data,columns=NEW_INDEX)</span><br><span class="line">    data = data.fillna(<span class="number">0</span>)</span><br><span class="line">    <span class="comment">#### Normalization</span></span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> NEW_INDEX:</span><br><span class="line">        maximum = data[col].max()</span><br><span class="line">        <span class="keyword">if</span> maximum &gt; <span class="number">0</span>:</span><br><span class="line">            data[col] /= maximum</span><br><span class="line">    <span class="comment">#### To List</span></span><br><span class="line">    temp = np.array(data)</span><br><span class="line">    data = [[torch.FloatTensor(temp[j][:FEATURES]),</span><br><span class="line">             torch.FloatTensor(ONE_HOT[int(temp[j][FEATURES])])] <span class="keyword">for</span> j <span class="keyword">in</span> range(temp.shape[<span class="number">0</span>])]</span><br><span class="line">    <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>
<br>
<h2 id="pytorch构建全连接深度神经网络"><a class="markdownIt-Anchor" href="#pytorch构建全连接深度神经网络"></a> PyTorch构建全连接深度神经网络</h2>
<p>本来的目的就是初学PyTorch，写个神经网络测试一下，才误打误撞找到了Kaggle这个比赛。直接通过<code>nn.Sequential()</code>和<code>add_module()</code>构建一个可以自由调参数的神经网络模板。激活函数都可以从若干中随意设定(为了方便选择以及输出参数采用了字典形式)。</p>
<p>注意<code>nn.Softmax()</code>是个坑人函数，其是针对多维设计的，必须要传入<code>axis=?</code>表示对第几维度求Softmax，因此一维Softmax应该为<code>nn.Softmax(0)</code>。</p>
<p>训练集总共<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>891</mn></mrow><annotation encoding="application/x-tex">891</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span><span class="mord">9</span><span class="mord">1</span></span></span></span>个数据，实际训练时将<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>800</mn></mrow><annotation encoding="application/x-tex">800</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span><span class="mord">0</span><span class="mord">0</span></span></span></span>个数据设定为真·训练集，其余<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>91</mn></mrow><annotation encoding="application/x-tex">91</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">9</span><span class="mord">1</span></span></span></span>个数据为验证集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">ACTIVATION = &#123;<span class="string">'sigmoid'</span>:nn.Sigmoid(),</span><br><span class="line">              <span class="string">'tanh'</span>:nn.Tanh(),</span><br><span class="line">              <span class="string">'ReLU'</span>:nn.ReLU(),</span><br><span class="line">              <span class="string">'softplus'</span>:nn.Softplus(),</span><br><span class="line">              <span class="string">'LeakyReLU'</span>:nn.LeakyReLU(),</span><br><span class="line">              <span class="string">'logsigmoid'</span>:nn.LogSigmoid(),</span><br><span class="line">              <span class="string">'PReLU'</span>:nn.PReLU(),</span><br><span class="line">              <span class="string">'ReLU6'</span>:nn.ReLU6(),</span><br><span class="line">              <span class="string">'softsign'</span>:nn.Softsign()</span><br><span class="line">             &#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FCDNN</span><span class="params">( nn.Module )</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">( self, nodes, activation )</span>:</span></span><br><span class="line">        super(FCDNN,self).__init__()</span><br><span class="line">        self.layers = nn.Sequential()</span><br><span class="line">        self.name = <span class="string">'FCDNN('</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nodes)<span class="number">-1</span>):</span><br><span class="line">            self.layers.add_module(<span class="string">'fc-&#123;0&#125;'</span>.format(i),nn.Linear(nodes[i],nodes[i+<span class="number">1</span>]))</span><br><span class="line">            self.layers.add_module(<span class="string">'activation-&#123;0&#125;'</span>.format(i),ACTIVATION[activation])</span><br><span class="line">            self.name += str(nodes[i])+<span class="string">'-'</span></span><br><span class="line">        self.name += str(nodes[len(nodes)<span class="number">-1</span>])+<span class="string">','</span>+activation+<span class="string">')'</span></span><br><span class="line">        self.layers.add_module(<span class="string">'softmax'</span>,nn.Softmax(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">( self, x )</span>:</span></span><br><span class="line">        x = self.layers(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">( self, loss_func, optimizer, eta, decay, train_data, validate_data, epoch, batch_num, batch_size )</span>:</span></span><br><span class="line">        print(<span class="string">'['</span>+self.name+<span class="string">' &#123;0&#125;*&#123;1&#125;*&#123;2&#125;'</span>.format(epoch,batch_num,batch_size)+<span class="string">'] with optimizer ['</span>+str(type(optimizer))+<span class="string">']:'</span>)</span><br><span class="line">        n = len(train_data)</span><br><span class="line">        m = len(validate_data)</span><br><span class="line">        <span class="keyword">for</span> E <span class="keyword">in</span> range(epoch):</span><br><span class="line">            np.random.shuffle(train_data)</span><br><span class="line">            p = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> T <span class="keyword">in</span> range(batch_num):</span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> range(batch_size):</span><br><span class="line">                    loss = loss_func(self.forward(train_data[p][<span class="number">0</span>]),train_data[p][<span class="number">1</span>])</span><br><span class="line">                    loss.backward()</span><br><span class="line">                    p = (p+<span class="number">1</span>)%n</span><br><span class="line">                optimizer.step()</span><br><span class="line">            eta *= decay</span><br><span class="line">            <span class="keyword">if</span> eta &lt; <span class="number">1e-6</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">for</span> p <span class="keyword">in</span> optimizer.param_groups:</span><br><span class="line">                p[<span class="string">'lr'</span>] *= decay</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            L = <span class="number">0.</span></span><br><span class="line">            R = <span class="number">0.</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> train_data:</span><br><span class="line">                t = self.forward(j[<span class="number">0</span>])</span><br><span class="line">                L += loss_func(t,j[<span class="number">1</span>])</span><br><span class="line">                R += float((t[<span class="number">0</span>]&lt;t[<span class="number">1</span>]) != (j[<span class="number">1</span>][<span class="number">0</span>]&lt;j[<span class="number">1</span>][<span class="number">1</span>]))</span><br><span class="line">            print(<span class="string">"\tTraining Loss = %.6f"</span>%(L/n))</span><br><span class="line">            print(<span class="string">"\tTraining Error Rate = %.4f%%"</span>%(R/n*<span class="number">100</span>))</span><br><span class="line">            L = <span class="number">0.</span></span><br><span class="line">            R = <span class="number">0.</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> validate_data:</span><br><span class="line">                t = self.forward(j[<span class="number">0</span>])</span><br><span class="line">                L += loss_func(t,j[<span class="number">1</span>])</span><br><span class="line">                R += float((t[<span class="number">0</span>]&lt;t[<span class="number">1</span>]) != (j[<span class="number">1</span>][<span class="number">0</span>]&lt;j[<span class="number">1</span>][<span class="number">1</span>]))</span><br><span class="line">            print(<span class="string">"\tValidation Loss = %.6f"</span>%(L/m))</span><br><span class="line">            print(<span class="string">"\tValidation Error Rate = %.4f%%"</span>%(R/m*<span class="number">100</span>))</span><br></pre></td></tr></table></figure>
<p>具体运行流程经历了多个版本。最开始是手动<s>瞎猜</s>调节神经网络的各个参数，后来开始手动编写网格式搜索参数，但是由于速度实在过慢令人难以忍受，于是随机化。</p>
<p>如此生成一个随机的全连接深度神经网络:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">ACTIVATION = &#123;<span class="string">'sigmoid'</span>:nn.Sigmoid(),</span><br><span class="line">              <span class="string">'tanh'</span>:nn.Tanh(),</span><br><span class="line">              <span class="string">'ReLU'</span>:nn.ReLU(),</span><br><span class="line">              <span class="string">'softplus'</span>:nn.Softplus(),</span><br><span class="line">              <span class="string">'LeakyReLU'</span>:nn.LeakyReLU(),</span><br><span class="line">              <span class="string">'logsigmoid'</span>:nn.LogSigmoid(),</span><br><span class="line">              <span class="string">'PReLU'</span>:nn.PReLU(),</span><br><span class="line">              <span class="string">'ReLU6'</span>:nn.ReLU6(),</span><br><span class="line">              <span class="string">'softsign'</span>:nn.Softsign()</span><br><span class="line">             &#125;</span><br><span class="line">EPOCH = <span class="number">500</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">RandomFCDNN</span><span class="params">( train_data, validate_data )</span>:</span></span><br><span class="line">    layers = [FEATURES]</span><br><span class="line">    L = np.random.randint(<span class="number">1</span>,<span class="number">5</span>)</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(L):</span><br><span class="line">        layers.append(<span class="number">2</span> ** np.random.randint(<span class="number">1</span>,<span class="number">7</span>))</span><br><span class="line">    layers.append(<span class="number">2</span>)</span><br><span class="line">    A = np.random.choice(list(ACTIVATION))</span><br><span class="line">    E = np.random.random()</span><br><span class="line">    W = np.random.randint(<span class="number">1</span>,<span class="number">8</span>)</span><br><span class="line">    B = <span class="number">0.99</span>+W/<span class="number">1200.</span></span><br><span class="line">    D = np.random.choice([<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">8</span>,<span class="number">10</span>,<span class="number">16</span>,<span class="number">20</span>,<span class="number">25</span>,<span class="number">32</span>])</span><br><span class="line">    N = FCDNN(layers,A)</span><br><span class="line">    O = np.random.choice([optim.SGD(N.parameters(),lr=E,momentum=np.random.random()*<span class="number">0.9</span>),</span><br><span class="line">                          optim.Adam(N.parameters(),lr=E),</span><br><span class="line">                          optim.Adagrad(N.parameters(),lr=E),</span><br><span class="line">                          optim.RMSprop(N.parameters(),lr=E,momentum=np.random.random()*<span class="number">0.9</span>)</span><br><span class="line">                         ])</span><br><span class="line">    N.train(nn.MSELoss(),O,E,B,train_data,validate_data,EPOCH*W,<span class="number">800</span>//D,D)</span><br><span class="line">    <span class="keyword">return</span> N.evaluate(validate_data,target_data)</span><br></pre></td></tr></table></figure>
<p>每一层神经网络节点数都是2的整倍数，介于<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>2</mn><mo>∼</mo><mn>128</mn></mrow><annotation encoding="application/x-tex">2 \sim 128</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">2</span><span class="mord">8</span></span></span></span>之间。初始学习率为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0</mn><mo>∼</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">0 \sim 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>之间的小数，然后以<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi><mo>=</mo><mn>0.99</mn><mo>+</mo><mfrac><mrow><mrow><mi mathvariant="monospace">e</mi><mi mathvariant="monospace">p</mi><mi mathvariant="monospace">o</mi><mi mathvariant="monospace">c</mi><mi mathvariant="monospace">h</mi></mrow><mi mathvariant="normal">/</mi><mn>500</mn></mrow><mn>1200</mn></mfrac></mrow><annotation encoding="application/x-tex">\beta = 0.99 + \frac{\mathtt{epoch}/500}{1200}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span><span class="mord">9</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.355em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">2</span><span class="mord mtight">0</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathtt mtight">e</span><span class="mord mathtt mtight">p</span><span class="mord mathtt mtight">o</span><span class="mord mathtt mtight">c</span><span class="mord mathtt mtight">h</span></span><span class="mord mtight">/</span><span class="mord mtight">5</span><span class="mord mtight">0</span><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>的速度进行衰减(手动构造+检验表明，当<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="monospace">e</mi><mi mathvariant="monospace">p</mi><mi mathvariant="monospace">o</mi><mi mathvariant="monospace">c</mi><mi mathvariant="monospace">h</mi></mrow><annotation encoding="application/x-tex">\mathtt{epoch}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.22222em;"></span><span class="mord"><span class="mord mathtt">e</span><span class="mord mathtt">p</span><span class="mord mathtt">o</span><span class="mord mathtt">c</span><span class="mord mathtt">h</span></span></span></span></span>介于<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>500</mn><mo>∼</mo><mn>5000</mn></mrow><annotation encoding="application/x-tex">500 \sim 5000</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">5</span><span class="mord">0</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">5</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span></span></span></span>之间时，这样一个衰减速率可以使得最终学习率保持在一个合理区间内)。由于训练集数据量比较小，<code>batch_size</code>也比较小，直接取了测试集大小<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>800</mn></mrow><annotation encoding="application/x-tex">800</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">8</span><span class="mord">0</span><span class="mord">0</span></span></span></span>的部分小约数。后来也尝试了直接固定学习率。</p>
<p>运行起来大约是这个样子:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[FCDNN(26-32-2-64-2,softplus) 3000*160*5] with optimizer [&lt;class &apos;torch.optim.adam.Adam&apos;&gt;]:</span><br><span class="line">    Training Loss = 0.111061</span><br><span class="line">    Training Error Rate = 14.5000%</span><br><span class="line">    Validation Loss = 0.123357</span><br><span class="line">    Validation Error Rate = 14.2857%</span><br></pre></td></tr></table></figure>
<br>
<h2 id="集成ensemble"><a class="markdownIt-Anchor" href="#集成ensemble"></a> 集成(Ensemble)</h2>
<p>集成就是对若干个不同参数的神经网络进行综合。~~要平等不要平均，~~对每个神经网络按照其在验证集上的表现进行加权，具体地，考虑错误率:</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>ε</mi><mi>k</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mn>1</mn><mrow><mi mathvariant="normal">∣</mi><mi>V</mi><mi mathvariant="normal">∣</mi></mrow></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi mathvariant="normal">∣</mi><mi>V</mi><mi mathvariant="normal">∣</mi></mrow></munderover><mo fence="false">[</mo><munder><mo><mtext>argmax</mtext></mo><mrow><mi>j</mi><mo>∈</mo><mo stretchy="false">{</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">}</mo></mrow></munder><mo fence="false">(</mo><msub><mrow><mi mathvariant="monospace">F</mi><mi mathvariant="monospace">C</mi><mi mathvariant="monospace">D</mi><mi mathvariant="monospace">N</mi><mi mathvariant="monospace">N</mi></mrow><mi>k</mi></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><msub><mo stretchy="false">)</mo><mi>j</mi></msub><mo fence="false">)</mo><mi mathvariant="normal">≠</mi><msub><mi>y</mi><mi>i</mi></msub><mo fence="false">]</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>ω</mi><mi>k</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>ln</mi><mo>⁡</mo><msqrt><mfrac><mrow><mn>1</mn><mo>−</mo><msub><mi>ε</mi><mi>k</mi></msub></mrow><msub><mi>ε</mi><mi>k</mi></msub></mfrac></msqrt></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow><mi mathvariant="monospace">O</mi><mi mathvariant="monospace">U</mi><mi mathvariant="monospace">T</mi><mi mathvariant="monospace">P</mi><mi mathvariant="monospace">U</mi><mi mathvariant="monospace">T</mi></mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><munder><mo><mtext>argmax</mtext></mo><mrow><mi>j</mi><mo>∈</mo><mo stretchy="false">{</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">}</mo></mrow></munder><mrow><mo fence="true">(</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>ω</mi><mi>k</mi></msub><mo>⋅</mo><msub><mrow><mi mathvariant="monospace">F</mi><mi mathvariant="monospace">C</mi><mi mathvariant="monospace">D</mi><mi mathvariant="monospace">N</mi><mi mathvariant="monospace">N</mi></mrow><mi>k</mi></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><msub><mo stretchy="false">)</mo><mi>j</mi></msub><mo fence="true">)</mo></mrow></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
\varepsilon_k &amp;= \frac{1}{\vert V \vert}\sum_{i=1}^{\vert V \vert} \Big[\underset{j \in \lbrace 0,1 \rbrace}{\text{argmax}}\big(\mathtt{FCDNN}_k(x_i)_j \big) \ne y_i \Big] \\
\omega_k &amp;= \ln \sqrt{\frac{1-\varepsilon_k}{\varepsilon_k}} \\
\mathtt{OUTPUT}(x_i) &amp;= \underset{j \in \lbrace 0,1 \rbrace}{\text{argmax}} \left( \sum_{k=1}^N \omega_k \cdot \mathtt{FCDNN}_k(x_i)_j \right) \\
\end{aligned}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:9.709123000000002em;vertical-align:-4.6045615em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.104561500000001em;"><span style="top:-7.104561500000001em;"><span class="pstrut" style="height:3.961005em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">ε</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.9502975000000005em;"><span class="pstrut" style="height:3.961005em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-0.9585565000000003em;"><span class="pstrut" style="height:3.961005em;"></span><span class="mord"><span class="mord"><span class="mord mathtt">O</span><span class="mord mathtt">U</span><span class="mord mathtt">T</span><span class="mord mathtt">P</span><span class="mord mathtt">U</span><span class="mord mathtt">T</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:4.6045615em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.104561500000001em;"><span style="top:-7.104561500000001em;"><span class="pstrut" style="height:3.961005em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mord">∣</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.9610050000000003em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.386005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathdefault mtight" style="margin-right:0.22222em;">V</span><span class="mord mtight">∣</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="delimsizing size2">[</span></span><span class="mord"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43056000000000016em;"><span style="top:-2.11456em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">∈</span><span class="mopen mtight">{</span><span class="mord mtight">0</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span><span class="mclose mtight">}</span></span></span></span><span style="top:-3.0000000000000004em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop"><span class="mord text"><span class="mord">argmax</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.16044em;"><span></span></span></span></span></span></span><span class="mord"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord"><span class="mord mathtt">F</span><span class="mord mathtt">C</span><span class="mord mathtt">D</span><span class="mord mathtt">N</span><span class="mord mathtt">N</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord"><span class="delimsizing size1">)</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel"><span class="mord"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.69444em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="rlap"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="inner"><span class="mrel"></span></span><span class="fix"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="delimsizing size2">]</span></span></span></span><span style="top:-3.9502975000000005em;"><span class="pstrut" style="height:3.961005em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mop">ln</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.576595em;"><span class="svg-align" style="top:-4.4em;"><span class="pstrut" style="height:4.4em;"></span><span class="mord" style="padding-left:1em;"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.3139999999999996em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">ε</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathdefault">ε</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8360000000000001em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-3.536595em;"><span class="pstrut" style="height:4.4em;"></span><span class="hide-tail" style="min-width:1.02em;height:2.48em;"><svg width="400em" height="2.48em" viewbox="0 0 400000 2592" preserveaspectratio="xMinYMin slice"><path d="M424,2478c-1.3,-0.7,-38.5,-172,-111.5,-514c-73,
-342,-109.8,-513.3,-110.5,-514c0,-2,-10.7,14.3,-32,49c-4.7,7.3,-9.8,15.7,-15.5,
25c-5.7,9.3,-9.8,16,-12.5,20s-5,7,-5,7c-4,-3.3,-8.3,-7.7,-13,-13s-13,-13,-13,
-13s76,-122,76,-122s77,-121,77,-121s209,968,209,968c0,-2,84.7,-361.7,254,-1079
c169.3,-717.3,254.7,-1077.7,256,-1081c4,-6.7,10,-10,18,-10H400000v40H1014.6
s-87.3,378.7,-272.6,1166c-185.3,787.3,-279.3,1182.3,-282,1185c-2,6,-10,9,-24,9
c-8,0,-12,-0.7,-12,-2z M1001 80H400000v40H1014z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.863405em;"><span></span></span></span></span></span></span></span><span style="top:-0.9585565000000003em;"><span class="pstrut" style="height:3.961005em;"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.43056000000000016em;"><span style="top:-2.11456em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">∈</span><span class="mopen mtight">{</span><span class="mord mtight">0</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span><span class="mclose mtight">}</span></span></span></span><span style="top:-3.0000000000000004em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop"><span class="mord text"><span class="mord">argmax</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.16044em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">(</span></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.8478869999999998em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.0500049999999996em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.300005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.302113em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord"><span class="mord mathtt">F</span><span class="mord mathtt">C</span><span class="mord mathtt">D</span><span class="mord mathtt">N</span><span class="mord mathtt">N</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size4">)</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:4.6045615em;"><span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>具体实现对于神经网络自身，定义评估权重的函数:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FCDNN</span><span class="params">( nn.Module )</span>:</span></span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">( self, validate_data, target_data )</span>:</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            E = <span class="number">0.</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> validate_data:</span><br><span class="line">                t = self.forward(j[<span class="number">0</span>])</span><br><span class="line">                E += (t[<span class="number">0</span>]&lt;t[<span class="number">1</span>]) != (j[<span class="number">1</span>][<span class="number">0</span>]&lt;j[<span class="number">1</span>][<span class="number">1</span>])</span><br><span class="line">            E /= len(validate_data)</span><br><span class="line">            weight = math.log(math.sqrt((<span class="number">1</span>-E)/E))</span><br><span class="line">            prediction = torch.zeros(len(target_data),<span class="number">2</span>)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(target_data)):</span><br><span class="line">                prediction[i] = self.forward(target_data[i][<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Special Limitation</span></span><br><span class="line">            <span class="keyword">if</span> E &gt; <span class="number">0.25</span>:</span><br><span class="line">                print(<span class="string">"Discarded!"</span>)</span><br><span class="line">                <span class="keyword">return</span> torch.zeros(len(target_data),<span class="number">2</span>)</span><br><span class="line">            <span class="keyword">return</span> prediction*weight</span><br></pre></td></tr></table></figure>
<p>因为某些优化器表现似乎不太稳定，于是添加了特殊限制: 验证集错误率超过<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0.25</mn></mrow><annotation encoding="application/x-tex">0.25</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">2</span><span class="mord">5</span></span></span></span>的网络的输出方案将被直接作废。</p>
<p>最终运行(其实一次划分真·测试集和验证集足够，<s>激进冒险主义者</s>为了引入更多随机性，每个网络重新划分):</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">output</span><span class="params">( prediction, filedir )</span>:</span></span><br><span class="line">    submission = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">892</span>,<span class="number">1310</span>):</span><br><span class="line">        submission.append([i,int(prediction[i<span class="number">-892</span>][<span class="number">0</span>]&lt;prediction[i<span class="number">-892</span>][<span class="number">1</span>])])</span><br><span class="line">    submission = pd.DataFrame(submission)</span><br><span class="line">    submission.columns = [<span class="string">'PassengerId'</span>,<span class="string">'Survived'</span>]</span><br><span class="line">    submission.to_csv(filedir,index=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">origin_data = preprocess(pd.read_csv(PATH+<span class="string">"train.csv"</span>))</span><br><span class="line">target_data = preprocess(pd.read_csv(PATH+<span class="string">"test.csv"</span>))</span><br><span class="line"><span class="comment"># predictions = evaluate_gender_submission(validate_data,target_data)</span></span><br><span class="line">predictions = torch.zeros(len(target_data),<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">begin = time.time()</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">    np.random.shuffle(origin_data)</span><br><span class="line">    train_data = origin_data[:<span class="number">800</span>].copy()</span><br><span class="line">    validate_data = origin_data[<span class="number">800</span>:].copy()</span><br><span class="line"></span><br><span class="line">    start = time.time()</span><br><span class="line">    predictions += RandomFCDNN(train_data,validate_data)</span><br><span class="line">    output(predictions,PATH+<span class="string">"submission.csv"</span>)</span><br><span class="line">    end = time.time()</span><br><span class="line">    print(<span class="string">'Time cost: %.4f s, total time cost: %.4f s'</span>%(end-start,end-begin))</span><br></pre></td></tr></table></figure>
<br>
<h2 id="完整代码"><a class="markdownIt-Anchor" href="#完整代码"></a> 完整代码</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># np.random.seed(998244353)</span></span><br><span class="line"><span class="comment"># torch.manual_seed(998244353)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Configurations</span></span><br><span class="line">OLD_INDEX = [<span class="string">'Pclass'</span>,<span class="string">'Sex'</span>,<span class="string">'Age'</span>,<span class="string">'UknAge'</span>,<span class="string">'SibSp'</span>,<span class="string">'Parch'</span>,<span class="string">'Fare'</span>,<span class="string">'Embarked'</span>,<span class="string">'Survived'</span>]</span><br><span class="line">NEW_INDEX = [<span class="string">'Age'</span>, <span class="string">'UknAge'</span>, <span class="string">'Fare'</span>,</span><br><span class="line">             <span class="string">'Pclass_0'</span>, <span class="string">'Pclass_1'</span>, <span class="string">'Pclass_2'</span>,</span><br><span class="line">             <span class="string">'Sex_0'</span>, <span class="string">'Sex_1'</span>,</span><br><span class="line">             <span class="string">'SibSp_0'</span>, <span class="string">'SibSp_1'</span>, <span class="string">'SibSp_2'</span>, <span class="string">'SibSp_3'</span>, <span class="string">'SibSp_4'</span>, <span class="string">'SibSp_5'</span>, <span class="string">'SibSp_8'</span>,</span><br><span class="line">             <span class="string">'Parch_0'</span>, <span class="string">'Parch_1'</span>, <span class="string">'Parch_2'</span>, <span class="string">'Parch_3'</span>, <span class="string">'Parch_4'</span>, <span class="string">'Parch_5'</span>, <span class="string">'Parch_6'</span>, <span class="string">'Parch_9'</span>,</span><br><span class="line">             <span class="string">'Embarked_0'</span>, <span class="string">'Embarked_1'</span>, <span class="string">'Embarked_2'</span>,</span><br><span class="line">             <span class="string">'Survived'</span></span><br><span class="line">            ]</span><br><span class="line">MAP_Sex = &#123;<span class="string">'male'</span>:<span class="number">0</span>,<span class="string">'female'</span>:<span class="number">1</span>&#125;</span><br><span class="line">MAP_Embarked = &#123;<span class="string">'C'</span>:<span class="number">0</span>,<span class="string">'Q'</span>:<span class="number">1</span>,<span class="string">'S'</span>:<span class="number">2</span>&#125;</span><br><span class="line">ONE_HOT = [[<span class="number">1</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">1</span>]]</span><br><span class="line">FEATURES = <span class="number">26</span></span><br><span class="line">ACTIVATION = &#123;<span class="string">'sigmoid'</span>:nn.Sigmoid(),</span><br><span class="line">              <span class="string">'tanh'</span>:nn.Tanh(),</span><br><span class="line">              <span class="string">'ReLU'</span>:nn.ReLU(),</span><br><span class="line">              <span class="string">'softplus'</span>:nn.Softplus(),</span><br><span class="line">              <span class="string">'LeakyReLU'</span>:nn.LeakyReLU(),</span><br><span class="line">              <span class="string">'logsigmoid'</span>:nn.LogSigmoid(),</span><br><span class="line">              <span class="string">'PReLU'</span>:nn.PReLU(),</span><br><span class="line">              <span class="string">'ReLU6'</span>:nn.ReLU6(),</span><br><span class="line">              <span class="string">'softsign'</span>:nn.Softsign()</span><br><span class="line">             &#125;</span><br><span class="line">EPOCH = <span class="number">500</span></span><br><span class="line">PATH = <span class="string">""</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess</span><span class="params">( data )</span>:</span></span><br><span class="line">    <span class="comment"># Data Cleaning</span></span><br><span class="line">    data = pd.DataFrame(data,columns=OLD_INDEX)</span><br><span class="line">    data[<span class="string">'UknAge'</span>] = data[<span class="string">'UknAge'</span>].fillna(<span class="number">0</span>)</span><br><span class="line">    data[<span class="string">'Survived'</span>] = data[<span class="string">'Survived'</span>].fillna(<span class="number">0</span>)</span><br><span class="line">    <span class="comment">#### print(data[data['Age'].isnull()])</span></span><br><span class="line">    data.loc[data[<span class="string">'Age'</span>].isnull(),<span class="string">'UknAge'</span>] = <span class="number">1</span></span><br><span class="line">    data[<span class="string">'Age'</span>] = data[<span class="string">'Age'</span>].fillna(<span class="number">0</span>)</span><br><span class="line">    <span class="comment">#### print(data[data['Fare'].isnull()])</span></span><br><span class="line">    data[<span class="string">'Fare'</span>] = data[<span class="string">'Fare'</span>].fillna(<span class="number">14.4</span>)</span><br><span class="line">    <span class="comment">#### print(data[data['Embarked'].isnull()])</span></span><br><span class="line">    data[<span class="string">'Embarked'</span>] = data[<span class="string">'Embarked'</span>].fillna(<span class="string">'C'</span>)</span><br><span class="line">    <span class="comment">#### One-hot Encoding</span></span><br><span class="line">    data[<span class="string">'Pclass'</span>] -= <span class="number">1</span></span><br><span class="line">    data[<span class="string">'Sex'</span>] = data[<span class="string">'Sex'</span>].map(MAP_Sex)</span><br><span class="line">    data[<span class="string">'Embarked'</span>] = data[<span class="string">'Embarked'</span>].map(MAP_Embarked)</span><br><span class="line">    data = pd.get_dummies(data,columns=[<span class="string">'Pclass'</span>,<span class="string">'Sex'</span>,<span class="string">'SibSp'</span>,<span class="string">'Parch'</span>,<span class="string">'Embarked'</span>])</span><br><span class="line">    data = pd.DataFrame(data,columns=NEW_INDEX)</span><br><span class="line">    data = data.fillna(<span class="number">0</span>)</span><br><span class="line">    <span class="comment">#### Normalization</span></span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> NEW_INDEX:</span><br><span class="line">        maximum = data[col].max()</span><br><span class="line">        <span class="keyword">if</span> maximum &gt; <span class="number">0</span>:</span><br><span class="line">            data[col] /= maximum</span><br><span class="line">    <span class="comment">#### To List</span></span><br><span class="line">    temp = np.array(data)</span><br><span class="line">    data = [[torch.FloatTensor(temp[j][:FEATURES]),</span><br><span class="line">             torch.FloatTensor(ONE_HOT[int(temp[j][FEATURES])])] <span class="keyword">for</span> j <span class="keyword">in</span> range(temp.shape[<span class="number">0</span>])]</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FCDNN</span><span class="params">( nn.Module )</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">( self, nodes, activation )</span>:</span></span><br><span class="line">        super(FCDNN,self).__init__()</span><br><span class="line">        self.layers = nn.Sequential()</span><br><span class="line">        self.name = <span class="string">'FCDNN'</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(nodes)<span class="number">-1</span>):</span><br><span class="line">            self.layers.add_module(<span class="string">'fc-&#123;0&#125;'</span>.format(i),nn.Linear(nodes[i],nodes[i+<span class="number">1</span>]))</span><br><span class="line">            self.layers.add_module(<span class="string">'activation-&#123;0&#125;'</span>.format(i),ACTIVATION[activation])</span><br><span class="line">            self.name += str(nodes[i])+<span class="string">'-'</span></span><br><span class="line">        self.name += str(nodes[len(nodes)<span class="number">-1</span>])+<span class="string">','</span>+activation+<span class="string">')'</span></span><br><span class="line">        self.layers.add_module(<span class="string">'softmax'</span>,nn.Softmax(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">( self, x )</span>:</span></span><br><span class="line">        x = self.layers(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">( self, loss_func, optimizer, eta, decay, train_data, validate_data, epoch, batch_num, batch_size )</span>:</span></span><br><span class="line">        print(<span class="string">'['</span>+self.name+<span class="string">' &#123;0&#125;*&#123;1&#125;*&#123;2&#125;'</span>.format(epoch,batch_num,batch_size)+<span class="string">'] with optimizer ['</span>+str(type(optimizer))+<span class="string">']:'</span>)</span><br><span class="line">        n = len(train_data)</span><br><span class="line">        m = len(validate_data)</span><br><span class="line">        <span class="keyword">for</span> E <span class="keyword">in</span> range(epoch):</span><br><span class="line">            np.random.shuffle(train_data)</span><br><span class="line">            p = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> T <span class="keyword">in</span> range(batch_num):</span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line">                <span class="keyword">for</span> j <span class="keyword">in</span> range(batch_size):</span><br><span class="line">                    loss = loss_func(self.forward(train_data[p][<span class="number">0</span>]),train_data[p][<span class="number">1</span>])</span><br><span class="line">                    loss.backward()</span><br><span class="line">                    p = (p+<span class="number">1</span>)%n</span><br><span class="line">                optimizer.step()</span><br><span class="line">            eta *= decay</span><br><span class="line">            <span class="keyword">if</span> eta &lt; <span class="number">1e-6</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">for</span> p <span class="keyword">in</span> optimizer.param_groups:</span><br><span class="line">                p[<span class="string">'lr'</span>] *= decay</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            L = <span class="number">0.</span></span><br><span class="line">            R = <span class="number">0.</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> train_data:</span><br><span class="line">                t = self.forward(j[<span class="number">0</span>])</span><br><span class="line">                L += loss_func(t,j[<span class="number">1</span>])</span><br><span class="line">                R += float((t[<span class="number">0</span>]&lt;t[<span class="number">1</span>]) != (j[<span class="number">1</span>][<span class="number">0</span>]&lt;j[<span class="number">1</span>][<span class="number">1</span>]))</span><br><span class="line">            print(<span class="string">"\tTraining Loss = %.6f"</span>%(L/n))</span><br><span class="line">            print(<span class="string">"\tTraining Error Rate = %.4f%%"</span>%(R/n*<span class="number">100</span>))</span><br><span class="line">            L = <span class="number">0.</span></span><br><span class="line">            R = <span class="number">0.</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> validate_data:</span><br><span class="line">                t = self.forward(j[<span class="number">0</span>])</span><br><span class="line">                L += loss_func(t,j[<span class="number">1</span>])</span><br><span class="line">                R += float((t[<span class="number">0</span>]&lt;t[<span class="number">1</span>]) != (j[<span class="number">1</span>][<span class="number">0</span>]&lt;j[<span class="number">1</span>][<span class="number">1</span>]))</span><br><span class="line">            print(<span class="string">"\tValidation Loss = %.6f"</span>%(L/m))</span><br><span class="line">            print(<span class="string">"\tValidation Error Rate = %.4f%%"</span>%(R/m*<span class="number">100</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">( self, validate_data, target_data )</span>:</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            R = <span class="number">0.</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> validate_data:</span><br><span class="line">                t = self.forward(j[<span class="number">0</span>])</span><br><span class="line">                R += float((t[<span class="number">0</span>]&lt;t[<span class="number">1</span>]) != (j[<span class="number">1</span>][<span class="number">0</span>]&lt;j[<span class="number">1</span>][<span class="number">1</span>]))</span><br><span class="line">            R /= len(validate_data)</span><br><span class="line">            weight = math.log(math.sqrt((<span class="number">1</span>-R)/R))</span><br><span class="line">            prediction = torch.zeros(len(target_data),<span class="number">2</span>)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(target_data)):</span><br><span class="line">                prediction[i] = self.forward(target_data[i][<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Special Limitation</span></span><br><span class="line">            <span class="keyword">if</span> R &gt; <span class="number">0.2</span>:</span><br><span class="line">                print(<span class="string">"Discarded!"</span>)</span><br><span class="line">                <span class="keyword">return</span> torch.zeros(len(target_data),<span class="number">2</span>)</span><br><span class="line">            <span class="keyword">return</span> prediction*weight</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">output</span><span class="params">( prediction, filedir )</span>:</span></span><br><span class="line">    submission = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">892</span>,<span class="number">1310</span>):</span><br><span class="line">        submission.append([i,int(prediction[i<span class="number">-892</span>][<span class="number">0</span>]&lt;prediction[i<span class="number">-892</span>][<span class="number">1</span>])])</span><br><span class="line">    submission = pd.DataFrame(submission)</span><br><span class="line">    submission.columns = [<span class="string">'PassengerId'</span>,<span class="string">'Survived'</span>]</span><br><span class="line">    submission.to_csv(filedir,index=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">RandomFCDNN</span><span class="params">( train_data, validate_data )</span>:</span></span><br><span class="line">    layers = [FEATURES]</span><br><span class="line">    L = np.random.randint(<span class="number">1</span>,<span class="number">5</span>)</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(L):</span><br><span class="line">        layers.append(<span class="number">2</span> ** np.random.randint(<span class="number">1</span>,<span class="number">7</span>))</span><br><span class="line">    layers.append(<span class="number">2</span>)</span><br><span class="line">    A = np.random.choice(list(ACTIVATION))</span><br><span class="line">    E = <span class="number">0.0001</span></span><br><span class="line">    W = np.random.randint(<span class="number">1</span>,<span class="number">8</span>)</span><br><span class="line">    B = <span class="number">1</span></span><br><span class="line">    D = np.random.choice([<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">8</span>,<span class="number">10</span>,<span class="number">16</span>,<span class="number">20</span>,<span class="number">25</span>,<span class="number">32</span>])</span><br><span class="line">    N = FCDNN(layers,A)</span><br><span class="line">    O = np.random.choice([optim.SGD(N.parameters(),lr=E,momentum=np.random.random()*<span class="number">0.9</span>),</span><br><span class="line">                          optim.Adam(N.parameters(),lr=E),</span><br><span class="line">                          optim.Adagrad(N.parameters(),lr=E),</span><br><span class="line">                          optim.RMSprop(N.parameters(),lr=E,momentum=np.random.random()*<span class="number">0.9</span>)</span><br><span class="line">                         ])</span><br><span class="line">    N.train(nn.MSELoss(),O,E,B,train_data,validate_data,EPOCH*W,<span class="number">800</span>//D,D)</span><br><span class="line">    <span class="keyword">return</span> N.evaluate(validate_data,target_data)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">origin_data = preprocess(pd.read_csv(PATH+<span class="string">"train.csv"</span>))</span><br><span class="line">target_data = preprocess(pd.read_csv(PATH+<span class="string">"test.csv"</span>))</span><br><span class="line"><span class="comment"># predictions = evaluate_gender_submission(validate_data,target_data)</span></span><br><span class="line">predictions = torch.zeros(len(target_data),<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">begin = time.time()</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">    np.random.shuffle(origin_data)</span><br><span class="line">    train_data = origin_data[:<span class="number">800</span>].copy()</span><br><span class="line">    validate_data = origin_data[<span class="number">800</span>:].copy()</span><br><span class="line"></span><br><span class="line">    start = time.time()</span><br><span class="line">    predictions += RandomFCDNN(train_data,validate_data)</span><br><span class="line">    output(predictions,PATH+<span class="string">"submission.csv"</span>)</span><br><span class="line">    end = time.time()</span><br><span class="line">    print(<span class="string">'Time cost: %.4f s, total time cost: %.4f s'</span>%(end-start,end-begin))</span><br></pre></td></tr></table></figure>
<p>注: 采用了固定学习率；验证集错误率限制改为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>0.2</mn></mrow><annotation encoding="application/x-tex">0.2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">2</span></span></span></span>；注意<code>PATH</code>未定义。<a href="https://www.kaggle.com/magolor/fully-connected-deep-neural-network" rel="external nofollow noopener noreferrer" target="_blank">Kaggle Kernel版本</a>。</p>
<br>
<h2 id="效果"><a class="markdownIt-Anchor" href="#效果"></a> 效果</h2>
<p>泰坦尼克数据集令人尴尬的一点在于，由于&quot;妇女和儿童先走&quot;，直接判断性别女为存活性别男为不存活就可以实现<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>76.555</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">76.555\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">7</span><span class="mord">6</span><span class="mord">.</span><span class="mord">5</span><span class="mord">5</span><span class="mord">5</span><span class="mord">%</span></span></span></span>的正确率。同时由于来自于真实的历史事件，数据是公开的，因此&quot;可以实现&quot;<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>100</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">100\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span><span class="mord">%</span></span></span></span>正确率。</p>
<p>目前实现的最优解为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>80.861</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">80.861\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">8</span><span class="mord">0</span><span class="mord">.</span><span class="mord">8</span><span class="mord">6</span><span class="mord">1</span><span class="mord">%</span></span></span></span>，在Top <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>6</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">6\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">6</span><span class="mord">%</span></span></span></span>的水平(作为Kaggle入门比赛，榜单每三个月会清零一次)，很可惜的是没能记录下参数。另外一个事实是，这一最优解是在没有Ensemble的情况下做到的(某次运行中第一个训练完成的神经网络)。</p>
<p><img src="/img/2020-01-12-blog-01/submission10.png" alt></p>
<p><img src="/img/2020-01-12-blog-01/6.png" alt></p>
<p>评论区中也有人猜测<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>83</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">83\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.80556em;vertical-align:-0.05556em;"></span><span class="mord">8</span><span class="mord">3</span><span class="mord">%</span></span></span></span>左右是最高的正确率，鉴于训练集过小，更高的模型都可能存在潜在的过拟合。</p>
<br>
<blockquote>
<p>扫描二维码即可在手机上查看这篇文章，或者转发二维码来分享这篇文章:</p>
</blockquote>
<p><img src="/img/2020-01-12-blog-01/QR_code.png" alt></p>
<br></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined" rel="external nofollow noopener noreferrer" target="_blank">Magolor</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://magolor.cn/2020/01/12/2020-01-12-blog-01/">https://magolor.cn/2020/01/12/2020-01-12-blog-01/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noopener noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://magolor.cn">Magolor</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/人工智能/">人工智能</a><a class="post-meta__tags" href="/tags/机器学习/">机器学习</a><a class="post-meta__tags" href="/tags/神经网络/">神经网络</a><a class="post-meta__tags" href="/tags/Kaggle/">Kaggle</a><a class="post-meta__tags" href="/tags/PyTorch/">PyTorch</a></div><div class="post-qr-code"><div class="post-qr-code-item"><img class="post-qr-code__img" src="/img/Magolor.png"><div class="post-qr-code__desc">扫描二维码在手机上查看或转发二维码以分享Magolor的博客</div></div></div><div class="addthis_inline_share_toolbox pull-right"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5c4b07a2561d21f6" async></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2020/01/14/2020-01-14-blog-01/"><i class="fa fa-chevron-left">  </i><span>PyTorch入门: Kaggle 猫狗识别VGG</span></a></div><div class="next-post pull-right"><a href="/2019/12/28/2019-12-28-blog-01/"><span>微积分A(1)期末复习笔记</span><i class="fa fa-chevron-right"></i></a></div></nav><div class="post-adv"><center><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="530" height="86" src="//music.163.com/outchain/player?type=2&id=1498842614&auto=0&height=66"></iframe></center></div><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: '60134c8112d0936f31e1',
  clientSecret: '0e44267dd38cbf3d995de5ed11a897b6385aff55',
  repo: 'magolor.github.io',
  owner: 'Magolor',
  admin: 'Magolor',
  id: md5(decodeURI(location.pathname)),
  language: 'zh-CN'
})
gitalk.render('gitalk-container')</script></div></div><footer class="footer-bg" style="background-image: url(/img/Beneath_the_Starlight_16-9.png)"><div class="layout" id="footer"><div class="copyright">&copy;2018 - 2020 By Magolor</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io" rel="external nofollow noopener noreferrer" target="_blank"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" rel="external nofollow noopener noreferrer" target="_blank"><span>Melody</span></a></div><div class="footer_custom_text">Fate is Fluid, Destiny is in the hands of Man.</div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.7.0"></script><script src="/js/fancybox.js?version=1.7.0"></script><script src="/js/sidebar.js?version=1.7.0"></script><script src="/js/copy.js?version=1.7.0"></script><script src="/js/fireworks.js?version=1.7.0"></script><script src="/js/transition.js?version=1.7.0"></script><script src="/js/scroll.js?version=1.7.0"></script><script src="/js/head.js?version=1.7.0"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script src="/js/katex.js"></script><script src="/js/search/local-search.js"></script><script id="ribbon" src="/js/third-party/canvas-ribbon.js" size="250" alpha="0.3" zindex="-2" data-click="false"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;" rel="external nofollow noopener noreferrer" target="_blank">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><!-- hexo-inject:begin --><!-- hexo-inject:end --><script async>window.onload=function(){var a=document.createElement('script'),b=document.getElementsByTagName('script')[0];a.type='text/javascript',a.async=!0,a.src='/sw-register.js?v='+Date.now(),b.parentNode.insertBefore(a,b)};</script></body></html>